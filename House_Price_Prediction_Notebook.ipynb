{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPk+bmQBOq/SqMulGJj0Pry",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BanafshehHassani/Deep-learning-end-to-end-by-using-TensorFlow-Keras-Hyperopt-and-MLflow/blob/main/House_Price_Prediction_Notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deep Learning: End-to-End House Price Prediction\n",
        "\n",
        "Author: [Banafsheh Hassani](https://www.linkedin.com/in/banafsheh-hassani-7b063a129/)\n",
        "\n",
        "This notebook demonstrates the process of building an end-to-end deep learning model for house price prediction using TensorFlow Keras, Hyperopt for hyperparameter tuning, and MLflow for experiment tracking and model management. The model is trained on the California Housing dataset from scikit-learn.\n",
        "\n",
        "Table of Contents\n",
        "Introduction\n",
        "Setup and Installation\n",
        "Data Loading and Preprocessing\n",
        "Model Building\n",
        "Model Training and Evaluation\n",
        "Hyperparameter Tuning\n",
        "Building the Final Model\n",
        "Predicting House Prices\n",
        "Model Deployment and Serving\n",
        "Conclusion\n",
        "1. Introduction\n",
        "In this notebook, we aim to build a deep learning model that predicts house prices based on various features such as the number of rooms, location, and other attributes. The California Housing dataset will be used for training and evaluation.\n",
        "\n",
        "2. Setup and Installation\n",
        "First, we need to install the necessary dependencies. Run the following commands to install TensorFlow, MLflow, Hyperopt, and other required libraries:"
      ],
      "metadata": {
        "id": "FnjktKs-LOfj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade tensorflow\n",
        "!pip install mlflow\n",
        "!pip install hyperopt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FVG10Vo7LfOs",
        "outputId": "31aa8e58-c7e3-4f83-b2b5-f29365886f1e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.13.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.1.21 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.56.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: keras<2.14,>=2.13.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.13.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.0)\n",
            "Requirement already satisfied: numpy<=1.24.3,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.22.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.14,>=2.13 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.13.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.13.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.5.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.32.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.40.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (3.4.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.27.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.3.6)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (3.2.2)\n",
            "Requirement already satisfied: mlflow in /usr/local/lib/python3.10/dist-packages (2.4.1)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (8.1.3)\n",
            "Requirement already satisfied: cloudpickle<3 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.2.1)\n",
            "Requirement already satisfied: databricks-cli<1,>=0.8.7 in /usr/local/lib/python3.10/dist-packages (from mlflow) (0.17.7)\n",
            "Requirement already satisfied: entrypoints<1 in /usr/local/lib/python3.10/dist-packages (from mlflow) (0.4)\n",
            "Requirement already satisfied: gitpython<4,>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.1.31)\n",
            "Requirement already satisfied: pyyaml<7,>=5.1 in /usr/local/lib/python3.10/dist-packages (from mlflow) (6.0)\n",
            "Requirement already satisfied: protobuf<5,>=3.12.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.20.3)\n",
            "Requirement already satisfied: pytz<2024 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2022.7.1)\n",
            "Requirement already satisfied: requests<3,>=2.17.3 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.27.1)\n",
            "Requirement already satisfied: packaging<24 in /usr/local/lib/python3.10/dist-packages (from mlflow) (23.1)\n",
            "Requirement already satisfied: importlib-metadata!=4.7.0,<7,>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (6.8.0)\n",
            "Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (0.4.4)\n",
            "Requirement already satisfied: alembic!=1.10.0,<2 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.11.1)\n",
            "Requirement already satisfied: docker<7,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (6.1.3)\n",
            "Requirement already satisfied: Flask<3 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.2.5)\n",
            "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.22.4)\n",
            "Requirement already satisfied: scipy<2 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.10.1)\n",
            "Requirement already satisfied: pandas<3 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.5.3)\n",
            "Requirement already satisfied: querystring-parser<2 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.2.4)\n",
            "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.0.16)\n",
            "Requirement already satisfied: scikit-learn<2 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.2.2)\n",
            "Requirement already satisfied: pyarrow<13,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (9.0.0)\n",
            "Requirement already satisfied: markdown<4,>=3.3 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.4.3)\n",
            "Requirement already satisfied: matplotlib<4 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.7.1)\n",
            "Requirement already satisfied: gunicorn<21 in /usr/local/lib/python3.10/dist-packages (from mlflow) (20.1.0)\n",
            "Requirement already satisfied: Jinja2<4,>=2.11 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.1.2)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.10/dist-packages (from alembic!=1.10.0,<2->mlflow) (1.2.4)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic!=1.10.0,<2->mlflow) (4.5.0)\n",
            "Requirement already satisfied: pyjwt>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from databricks-cli<1,>=0.8.7->mlflow) (2.7.0)\n",
            "Requirement already satisfied: oauthlib>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from databricks-cli<1,>=0.8.7->mlflow) (3.2.2)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from databricks-cli<1,>=0.8.7->mlflow) (0.8.10)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from databricks-cli<1,>=0.8.7->mlflow) (1.16.0)\n",
            "Requirement already satisfied: urllib3<2.0.0,>=1.26.7 in /usr/local/lib/python3.10/dist-packages (from databricks-cli<1,>=0.8.7->mlflow) (1.26.16)\n",
            "Requirement already satisfied: websocket-client>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from docker<7,>=4.0.0->mlflow) (1.6.0)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from Flask<3->mlflow) (2.3.6)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask<3->mlflow) (2.1.2)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython<4,>=2.1.0->mlflow) (4.0.10)\n",
            "Requirement already satisfied: setuptools>=3.0 in /usr/local/lib/python3.10/dist-packages (from gunicorn<21->mlflow) (67.7.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata!=4.7.0,<7,>=3.7.0->mlflow) (3.15.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2<4,>=2.11->mlflow) (2.1.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (4.40.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (1.4.4)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (3.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (2.8.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.17.3->mlflow) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.17.3->mlflow) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.17.3->mlflow) (3.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2->mlflow) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2->mlflow) (3.1.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow) (2.0.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython<4,>=2.1.0->mlflow) (5.0.0)\n",
            "Requirement already satisfied: hyperopt in /usr/local/lib/python3.10/dist-packages (0.2.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from hyperopt) (1.22.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from hyperopt) (1.10.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from hyperopt) (1.16.0)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from hyperopt) (3.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from hyperopt) (0.18.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from hyperopt) (4.65.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from hyperopt) (2.2.1)\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.10/dist-packages (from hyperopt) (0.10.9.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, import the required libraries for the project:"
      ],
      "metadata": {
        "id": "TupqwOeLLh5Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.models import Sequential\n",
        "import mlflow\n",
        "import mlflow.keras\n",
        "import mlflow.tensorflow\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from hyperopt import fmin, hp, tpe, STATUS_OK, SparkTrials\n"
      ],
      "metadata": {
        "id": "dF3MvouVLlhN"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Data Loading and Preprocessing\n",
        "Load the California Housing dataset from scikit-learn and split it into training and test sets. Perform feature scaling using StandardScaler:"
      ],
      "metadata": {
        "id": "nier0As-Lmz_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cal_housing = fetch_california_housing()\n",
        "X_train, X_test, y_train, y_test = train_test_split(cal_housing.data, cal_housing.target, test_size=0.2)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n"
      ],
      "metadata": {
        "id": "aN1ihM4XLsyk"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Model Building\n",
        "Define the architecture of the neural network model using TensorFlow Keras. In this example, we use a simple feedforward network:"
      ],
      "metadata": {
        "id": "Zu2v1J-QLvTX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model():\n",
        "    model = Sequential()\n",
        "    model.add(Dense(20, input_dim=8, activation=\"relu\"))\n",
        "    model.add(Dense(20, activation=\"relu\"))\n",
        "    model.add(Dense(1, activation=\"linear\"))\n",
        "    return model\n",
        "\n",
        "model = create_model()\n",
        "model.compile(loss=\"mse\", optimizer=\"Adam\", metrics=[\"mse\"])\n"
      ],
      "metadata": {
        "id": "UCvnWWAhL26x"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "wk7cEeqDL95-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Model Training and Evaluation\n",
        "Train the initial model using the training data and evaluate it on the test data. Also, set up callbacks for model checkpoints, early stopping, and logging training metrics to TensorBoard:"
      ],
      "metadata": {
        "id": "ma3UFylkMHz2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "experiment_log_dir = \"/dbfs/Banafshhassani@gmail.com/tb\"\n",
        "checkpoint_path = \"/dbfs/Banafshhassani@gmail.com/keras_checkpoint_weights.ckpt\"\n",
        "\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=experiment_log_dir)\n",
        "model_checkpoint = ModelCheckpoint(filepath=checkpoint_path, verbose=1, save_best_only=True)\n",
        "early_stopping = EarlyStopping(monitor=\"loss\", mode=\"min\", patience=3)\n",
        "\n",
        "history = model.fit(X_train, y_train, validation_split=.2, epochs=35, callbacks=[tensorboard_callback, model_checkpoint, early_stopping])\n",
        "\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir $experiment_log_dir\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fEEydx3qMOAO",
        "outputId": "cc505491-c54a-4e6f-9063-481b0e99de7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/35\n",
            "405/413 [============================>.] - ETA: 0s - loss: 1.4014 - mse: 1.4014\n",
            "Epoch 1: val_loss improved from inf to 0.61794, saving model to /dbfs/Banafshhassani@gmail.com/keras_checkpoint_weights.ckpt\n",
            "413/413 [==============================] - 8s 15ms/step - loss: 1.3854 - mse: 1.3854 - val_loss: 0.6179 - val_mse: 0.6179\n",
            "Epoch 2/35\n",
            "411/413 [============================>.] - ETA: 0s - loss: 0.5374 - mse: 0.5374\n",
            "Epoch 2: val_loss improved from 0.61794 to 0.46937, saving model to /dbfs/Banafshhassani@gmail.com/keras_checkpoint_weights.ckpt\n",
            "413/413 [==============================] - 7s 16ms/step - loss: 0.5378 - mse: 0.5378 - val_loss: 0.4694 - val_mse: 0.4694\n",
            "Epoch 3/35\n",
            "411/413 [============================>.] - ETA: 0s - loss: 0.4294 - mse: 0.4294\n",
            "Epoch 3: val_loss improved from 0.46937 to 0.42418, saving model to /dbfs/Banafshhassani@gmail.com/keras_checkpoint_weights.ckpt\n",
            "413/413 [==============================] - 4s 10ms/step - loss: 0.4290 - mse: 0.4290 - val_loss: 0.4242 - val_mse: 0.4242\n",
            "Epoch 4/35\n",
            "407/413 [============================>.] - ETA: 0s - loss: 0.3990 - mse: 0.3990\n",
            "Epoch 4: val_loss improved from 0.42418 to 0.40619, saving model to /dbfs/Banafshhassani@gmail.com/keras_checkpoint_weights.ckpt\n",
            "413/413 [==============================] - 4s 10ms/step - loss: 0.3981 - mse: 0.3981 - val_loss: 0.4062 - val_mse: 0.4062\n",
            "Epoch 5/35\n",
            "408/413 [============================>.] - ETA: 0s - loss: 0.3852 - mse: 0.3852\n",
            "Epoch 5: val_loss improved from 0.40619 to 0.39369, saving model to /dbfs/Banafshhassani@gmail.com/keras_checkpoint_weights.ckpt\n",
            "413/413 [==============================] - 6s 13ms/step - loss: 0.3852 - mse: 0.3852 - val_loss: 0.3937 - val_mse: 0.3937\n",
            "Epoch 6/35\n",
            "409/413 [============================>.] - ETA: 0s - loss: 0.3741 - mse: 0.3741\n",
            "Epoch 6: val_loss improved from 0.39369 to 0.37771, saving model to /dbfs/Banafshhassani@gmail.com/keras_checkpoint_weights.ckpt\n",
            "413/413 [==============================] - 6s 14ms/step - loss: 0.3741 - mse: 0.3741 - val_loss: 0.3777 - val_mse: 0.3777\n",
            "Epoch 7/35\n",
            "413/413 [==============================] - ETA: 0s - loss: 0.3650 - mse: 0.3650\n",
            "Epoch 7: val_loss improved from 0.37771 to 0.37500, saving model to /dbfs/Banafshhassani@gmail.com/keras_checkpoint_weights.ckpt\n",
            "413/413 [==============================] - 3s 8ms/step - loss: 0.3650 - mse: 0.3650 - val_loss: 0.3750 - val_mse: 0.3750\n",
            "Epoch 8/35\n",
            "277/413 [===================>..........] - ETA: 0s - loss: 0.3552 - mse: 0.3552"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "experiment_log_dir = \"/dbfs/Banafshhassani@gmail.com/tb\"\n",
        "checkpoint_path = \"/dbfs/Banafshhassani@gmail.com/keras_checkpoint_weights.ckpt\"\n",
        "\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=experiment_log_dir)\n",
        "model_checkpoint = ModelCheckpoint(filepath=checkpoint_path, verbose=1, save_best_only=True)\n",
        "early_stopping = EarlyStopping(monitor=\"loss\", mode=\"min\", patience=3)\n",
        "\n",
        "history = model.fit(X_train, y_train, validation_split=.2, epochs=35, callbacks=[tensorboard_callback, model_checkpoint, early_stopping])\n",
        "\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir $experiment_log_dir\n"
      ],
      "metadata": {
        "id": "zIyp_5qAMQTw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Hyperparameter Tuning\n",
        "Perform hyperparameter tuning using Hyperopt and MLflow. Define the search space and create an objective function for the tuning process:"
      ],
      "metadata": {
        "id": "PM12XCS-MZGT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(n):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(int(n[\"dense_l1\"]), input_dim=8, activation=\"relu\"))\n",
        "    model.add(Dense(int(n[\"dense_l2\"]), activation=\"relu\"))\n",
        "    model.add(Dense(1, activation=\"linear\"))\n",
        "    return model\n",
        "\n",
        "def runNN(n):\n",
        "    # ... (model training code)\n",
        "\n",
        "space = {\n",
        "    \"dense_l1\": hp.quniform(\"dense_l1\", 10, 30, 1),\n",
        "    \"dense_l2\": hp.quniform(\"dense_l2\", 10, 30, 1),\n",
        "    \"learning_rate\": hp.loguniform(\"learning_rate\", -5, 0),\n",
        "    \"optimizer\": hp.choice(\"optimizer\", [\"Adadelta\", \"Adam\"])\n",
        "}\n",
        "\n",
        "spark_trials = SparkTrials()\n",
        "\n",
        "with mlflow.start_run():\n",
        "    best_hyperparam = fmin(fn=runNN, space=space, algo=tpe.suggest, max_evals=30, trials=spark_trials)\n"
      ],
      "metadata": {
        "id": "hvqhcnaxMab3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Building the Final Model\n",
        "Build the final model using the best hyperparameters obtained from the tuning process. Modify the model architecture and compile it:"
      ],
      "metadata": {
        "id": "pB1PVtcdMdJD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import hyperopt\n",
        "\n",
        "first_layer = hyperopt.space_eval(space, best_hyperparam)[\"dense_l1\"]\n",
        "second_layer = hyperopt.space_eval(space, best_hyperparam)[\"dense_l2\"]\n",
        "learning_rate = hyperopt.space_eval(space, best_hyperparam)[\"learning_rate\"]\n",
        "optimizer = hyperopt.space_eval(space, best_hyperparam)[\"optimizer\"]\n",
        "\n",
        "optimizer_call = getattr(tf.keras.optimizers, optimizer)\n",
        "optimizer = optimizer_call(learning_rate=learning_rate)\n",
        "\n",
        "def create_new_model():\n",
        "    model = Sequential()\n",
        "    model.add(Dense(first_layer, input_dim=8, activation=\"relu\"))\n",
        "    model.add(Dense(second_layer, activation=\"relu\"))\n",
        "    model.add(Dense(1, activation=\"linear\"))\n",
        "    return model\n",
        "\n",
        "new_model = create_new_model()\n",
        "new_model.compile(loss=\"mse\", optimizer=optimizer, metrics=[\"mse\"])\n"
      ],
      "metadata": {
        "id": "oq308ht-MgmU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. Predicting House Prices\n",
        "Create a function that takes input features and returns the predicted house prices. Use this function to predict house prices for a sample input:"
      ],
      "metadata": {
        "id": "a4LAsIagMjXh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_house_prices(model, features):\n",
        "    scaled_features = scaler.transform([features])\n",
        "    predicted_price = model.predict(scaled_features)\n",
        "    return predicted_price[0][0]\n",
        "\n",
        "sample_input = [1.5, 3, 2, 1, 4, 5, 6, 7]  # Sample input features\n",
        "predicted_price = predict_house_prices(new_model, sample_input)\n",
        "\n",
        "print(\"Predicted House Price: $\", predicted_price)\n"
      ],
      "metadata": {
        "id": "zI2GRVuaMl63"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. Model Deployment and Serving\n",
        "To deploy and serve the model, you can use your preferred deployment method such as Flask or FastAPI to expose the model as a REST API endpoint.\n",
        "\n",
        "10. Conclusion\n",
        "In this notebook, we have demonstrated the end-to-end process of building a deep learning model for house price prediction using TensorFlow Keras, Hyperopt, and MLflow. The model was trained, evaluated, and tuned to obtain the best hyperparameters. Finally, we showcased how to use the trained model to predict house prices on new input data."
      ],
      "metadata": {
        "id": "MiK5xa7cMoJj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "JTeR76KpMTgw"
      }
    }
  ]
}